# AI Security Lab

Hands-on implementations of AI/ML security systems, built from first principles.

## About This Project

This repository documents my journey from cybersecurity professional to AI security engineer. Every algorithm is implemented from scratch to build deep understanding—not just library calls.

**Background:** Master's in Cybersecurity | Security Architecture | Threat Modeling

**Goal:** Bridge the gap between AI/ML and cybersecurity—building systems that can detect, defend, and assess AI-powered threats.

## Repository Structure

```
week-01-python-foundations/
week-02-math-and-data/
week-03-ml-algorithms/
week-04-neural-networks/
week-05-deep-learning/
week-06-production-ml/
week-07-adversarial-ml/
week-08-adversarial-ml-practice/
week-09-llm-security/
week-10-capstone/
week-11-portfolio/
week-12-integration/
```

## Projects

| Week | Focus | Key Project |
|------|-------|-------------|
| 1 | Python Foundations | Security Event Logger |
| 2 | Math for ML | Batch Threat Scorer |
| 3 | ML Algorithms | *Coming soon* |
| 4-6 | Deep Learning | *Coming soon* |
| 7-9 | AI Security | *Coming soon* |
| 10-12 | Capstone | *Coming soon* |

## Core Skills Demonstrated

- **From-scratch implementations:** Not just sklearn.fit()—actual algorithm internals
- **Security-first thinking:** Every project framed around threat detection and defense
- **Mathematical foundations:** Linear algebra, statistics, optimization theory
- **Production mindset:** Clean code, documentation, reproducibility

## Tech Stack

- Python 3.x
- NumPy / Pandas
- Scikit-learn
- PyTorch
- Matplotlib / Seaborn

## Connect

Building toward AI Security Engineer roles. Open to collaboration on adversarial ML and LLM security research.
